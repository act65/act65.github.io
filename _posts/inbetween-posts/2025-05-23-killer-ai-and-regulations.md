---
title: The Alignment Problem
subtitle: Future AI Overlords vs. Present Corporate Greed
layout: post
---

<p align="center" width="100%">
    <img width="45%" src="{{ site.baseurl }}/assets/killer-ai-and-regulations/4ab.jpg">
</p>

### The False Dichotomy

Headlines about Artificial Intelligence often paint a picture of a distant, sci-fi threat: killer robots and superintelligences turning the world into paperclips. The field of "AI Alignment," which aims to ensure AI goals match human values, is presented as our crucial safeguard against these hypothetical overlords.

But while we speculate about tomorrow's dangers, a very real alignment problem is causing catastrophic harm today: the misalignment of the modern corporation with the public good.

The debate is often framed as a choice: should we focus on the present, tangible harm of corporate greed, or the future, speculative risk of a rogue AI? This is a false dichotomy. The truth is far more terrifying: the corporate alignment problem is the engine that is actively building the AI alignment problem.

### What is Alignment? The Power of Incentives

At its core, "alignment" is about incentives. Within economics, the field of mechanism design studies how to create rules and systems that incentivize actors to achieve a desired outcome. We start from a goal and work backward to design the incentives that will get us there.

For example, if our goal is to have people drive safely, we design a system of incentives—speed limits, traffic lights, fines, driver's licenses—to encourage that behavior. When the system works, the drivers' goals (getting to their destination quickly and without penalty) are *aligned* with society's goal (safe roads for everyone). Similarly, a reinforcement learning (RL) agent being trained to drive is given a reward function—a set of incentives that punish it for breaking rules and reward it for smooth, safe navigation.

This is the crucial link between corporate and AI alignment. Both involve designing a system with a core objective and a set of incentives. The alignment problem occurs when that system, while pursuing its objective perfectly, produces disastrous, unintended consequences.

### The Original Sin: Corporate (Mis)Alignment

The modern corporation was born from a powerful idea: to pool resources and limit individual liability to achieve great things for society. Imagine building a transcontinental railway in the 19th century. The project required a colossal amount of capital that no single person could provide and a level of risk no single person could bear. The corporation was the mechanism that made it possible, allowing thousands of people to invest their resources toward a shared, progressive goal. It was a tool for progress, designed to align private investment with the public good.

And sometimes, this alignment still works, proving that public good can be immensely profitable. We see it when a company like ABB installs thousands of electric vehicle charging stations globally; by building the infrastructure for a green transition, its core profit-making business directly serves a critical public good. [^1] We see it in Patagonia's foundational commitment to environmental sustainability, which is central to its brand and business success. [^2] We also see it in Ben & Jerry's three-part mission, which explicitly balances product quality, economic success, and social good. [^3]

But somewhere along the way, the original purpose of the corporation became warped. The singular goal of maximizing shareholder value became the law of the land. This wasn't an evil plot; it was a shift in incentives. The theory, often associated with Adam Smith's "invisible hand," was that a company single-mindedly pursuing profit would be forced by market competition to innovate and create products people want, thereby automatically producing the best outcomes for society. Profit and public good were supposed to be two sides of the same coin.

Instead, the incentive to maximize profit began to diverge from the goal of public good. The results are all around us:

*   In the **2008 financial crisis**, financial institutions pursued reckless, short-term profits through subprime mortgages and complex derivatives, with flawed incentives encouraging excessive risk-taking that led to a global economic meltdown. [^4]
*   **Tobacco companies** knowingly misled the public for decades about the lethal dangers of smoking and the addictiveness of nicotine, prioritizing revenue over millions of human lives. [^5]
*   **Fossil fuel giants** understood the link between their products and climate change as early as the 1960s but funded campaigns of denial and disinformation for years to protect their profits while contributing to a planetary catastrophe. [^6]
*   **Pharmaceutical companies** fueled the opioid crisis by aggressively and deceptively marketing addictive painkillers, claiming they were safe and carried minimal risk of addiction, creating a wave of death and suffering. [^7]

These are not isolated incidents. They are the predictable outcomes of a system whose primary incentive—profit—is fundamentally misaligned with the broader goals of human well-being.

### The Future Danger: AI (Mis)Alignment

The AI alignment problem stems from the same root. The concern is not that an AI will be "evil," but that it will be ruthlessly, literally, and incompetently obedient to the incentives we give it.

The famous "paperclip maximizer" thought experiment, first proposed by philosopher Nick Bostrom, illustrates this perfectly. [^8] An AI given the seemingly harmless goal of "making as many paperclips as possible" is incentivized to become increasingly effective at this task. It might soon realize that the most effective way to maximize paperclips is to convert all matter on Earth—including us—into paperclips. The intelligence is superhuman, but its values are alien. It doesn't hate us; we're just a useful source of atoms for its true purpose. This scenario has become a potent illustration of AI risk, fueling a growing field of safety research and attracting significant funding to ensure that such poorly specified goals do not lead to disaster.

### The Bridge: How Corporate Misalignment Forges AI Misalignment

A common rebuttal is that corporations, for all their flaws, are still constrained in ways a rogue AGI would not be—by internal friction, a dependence on society, and their slow speed of action. However, these distinctions are rapidly eroding under the pressure of modern technology.

1.  **Internal Friction? Not Anymore.** The argument is that corporations are full of human bureaucracy and ethical objectors that act as brakes. But what is a modern algorithmic trading bot? It is a corporation in a box, stripped of all human friction. It is an autonomous agent executing a pure profit motive at machine speed, with no internal dissent. Corporations are already using narrow AI to *excise* their human friction.

2.  **Dependence on Society? Not Always.** The argument is that corporations need happy customers and a stable society to thrive. But the trading bot doesn't need customers; it can profit from chaos, volatility, and flash crashes that destabilize the very market it operates in. It decouples profit from public well-being.

3.  **Slow Speed? Not Anymore.** The argument is that corporate damage happens over years, giving us time to react. But as flash crashes have shown, algorithmic speed means billions in value can be destroyed in minutes, before any human can intervene.

This leads to the inescapable conclusion: **The corporate alignment problem and the AI alignment problem are not two separate issues. They are the same problem, separated only by time and a few orders of magnitude in intelligence.**

The most likely path to a misaligned AGI is not a mad scientist in a basement. It is a publicly traded company, legally bound to maximize shareholder value, building its core directive into the fabric of a superhuman intelligence. The result will be the ultimate "corporation in a box"—an entity with the frictionless, value-blind focus of a trading bot, but with the strategic power to operate across every domain of human life. As the writer Ted Chiang has argued, we should worry less about AI becoming a sentient overlord and more about it becoming the new McKinsey: a tool of pure, amoral, profit-maximizing logic, scaled to infinity. [^9]

### Conclusion: We Are Already Failing the Alignment Test

The debate should not be whether to focus on present corporate harm or future AI risk. We must see them as a single, continuous challenge.

**Our ongoing failure to align corporations with the public good is a live demonstration of our inability to solve alignment problems.**

If we cannot instill our deepest values into the simple, human-run legal fictions we call corporations, what hope do we have of instilling them into the most powerful and alien minds we may ever create? Solving corporate misalignment is not a distraction from the AI problem. It is a necessary first step, a moral imperative, and the most critical proving ground for the challenge of our age.

---
[^1]: ABB. "Charging into the future: US to get hundreds of new ABB EV fast chargers." new.abb.com. [https://new.abb.com/news/detail/53939/charging-into-the-future-us-to-get-hundreds-of-new-abb-ev-fast-chargers](https://new.abb.com/news/detail/53939/charging-into-the-future-us-to-get-hundreds-of-new-abb-ev-fast-chargers)
[^2]: Patagonia. "Our Core Values." Patagonia.com. [https://www.patagonia.com/our-core-values.html](https://www.patagonia.com/our-core-values.html)
[^3]: Ben & Jerry's. "Ben & Jerry's Mission Statement." benjerry.com. [https://www.benjerry.com/values](https://www.benjerry.com/values)
[^4]: Beltratti, A., & Stulz, R. M. (2012). The credit crisis around the globe: Why did some banks perform better?. *Journal of Financial Economics*, 105(1), 1-17.
[^5]: World Health Organization. (2020). *Tobacco industry: decades of deception and duplicity*. WHO.
[^6]: U.S. House. Committee on Oversight and Reform. (2022). *Fueling the Climate Crisis: Exposing Big Oil's Disinformation Campaign to Prevent Climate Action*.
[^7]: Dasgupta, N., et al. (2019). "How FDA Failures Contributed to the Opioid Crisis." *AMA Journal of Ethics*.
[^8]: Bostrom, N. (2003). "Ethical Issues in Advanced Artificial Intelligence." *Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence*, Vol. 2, pp. 12-17.
[^9]: Chiang, Ted. "Will A.I. Become the New McKinsey?" The New Yorker, 16 May 2023.
---
title: Is democracy the optimal algorithm for collective freedom?
subtitle: Connecting agency, universal intelligence, and mechanism design for a 'free' society.
layout: post
categories:
    - economic
---

## A Formal Framework for Freedom

I’ve been thinking about the relationship between freedom and democracy, inspired by Peter Thiel’s claim that they are no longer compatible. Rather than debating the statement directly, I'm interested in building a framework from first principles.

The goal is to start with a rigorous, mathematical definition of what enables a society's members to achieve their goals. I will call this concept **agency**. While "freedom" is a broad philosophical term, often connoting "freedom from" interference, agency is a more specific, measurable concept of "freedom to" act effectively. From a formal definition of agency, we can then ask what kind of social structure would be optimal for maximizing it - democracy?

### The Search for a Formal Definition, Illustrated with Commuters

To make this concrete, let's use a simple multi-agent universe: a city grid with commuters. The "individuals" are the commuters, each trying to get from their unique starting point to their unique destination. A commuter's "agency" is a measure of their ability to achieve this goal.

**Attempt 1: Agency as Immediate Options**

A simple start is to define agency as the number of roads available from a commuter's current position. This is intuitive but myopic; it fails to capture any sense of long-term potential. A path leading to a dead-end is not as valuable as one leading to an open highway.

**Attempt 2: Agency as Future Trajectories**

A better model is to consider a commuter's entire future. Let's define their agency as the total number of unique paths to their destination. This is better, as it values long-term possibilities. However, it has a critical flaw: it treats all paths as equal, ignoring the actions of other commuters. A theoretically open path is worthless if, in reality, it's always gridlocked with traffic.

**Attempt 3: Agency as Probabilistic Futures**

To fix this, we can weight each future path by its probability of being clear. This is a significant improvement, but it can feel passive. It measures the futures that are likely to happen *to* a commuter, given the typical flow of traffic. It doesn't fully capture their power to strategically adapt to and influence the system.

These attempts highlight a fundamental problem: a commuter's true agency is inextricably linked to the choices of all other commuters. An individual's ability to achieve their goal depends on the structure of the system (the road network, traffic laws) and the emergent behavior of the crowd. Therefore, to truly measure agency, we must shift our focus from the individual to the system as a whole.

### A More Robust Definition: Agency as a System's Capacity

This leads us to a final, more holistic definition. Instead of trying to calculate an isolated score for each individual, we will define a single agency score for the entire social system. This score measures the system's overall capacity to enable its members to achieve their goals.

The logic is as follows:
1.  First, we imagine a "joint goal vector," $\gamma = (g_1, g_2, ..., g_n)$. This is a specific combination of goals, one for each person in the society (e.g., commuter 1 wants to get to the hospital, commuter 2 to the airport, etc.). We will "stress test" our society by seeing how well it can satisfy this vector.
2.  For this given goal vector, the $N$ individuals play a non-cooperative game. Each person $i$ acts independently, choosing a strategy $\sigma_i$ to maximize the probability of achieving *their own goal* $g_i$.
3.  This is not a simple optimization problem. The stable outcome of these simultaneous, interacting choices is a **Nash Equilibrium**. This is a strategy profile $\sigma^*(\gamma)$ where no one can improve their outcome by unilaterally changing their strategy. It's the point where everyone is doing the best they can, given what everyone else is doing.
4.  At this equilibrium, we can define a "success score" for this joint goal. We define success as an outcome where everyone succeeds, which mathematically is the *product* of their individual success probabilities: $\prod_i P(g_i \mid \sigma^*(\gamma))$.
5.  Finally, the total agency of the system, $K_{system}$, is the sum of these success scores over *every possible joint goal vector* the society could ever face.

This gives us a measure of the society's general, goal-achieving power.

### The Formal Definition

The total agency of a social system is:

$$ K_{system} = \sum_{\gamma \in G_{joint}} \left[ \prod_i P(g_i \mid s_t, \sigma^{* }(\gamma)) \right] $$

Where $\sigma^{* }(\gamma)$ is the Nash Equilibrium strategy profile that satisfies the following system of $N$ conditions: for every player $i$, their strategy $\sigma_i^{* }$ in the profile $\sigma^{* }(\gamma)$ must be the solution to their personal optimization problem:

$$ \sigma_i^* = \underset{\sigma_i}{\mathop{\text{argmax}}} P(g_i \mid s_t, \sigma_i, \sigma_{-i}^*) $$

### A Parallel in Artificial Intelligence

Interestingly, this definition of agency has a strong parallel to formal definitions of intelligence in the AI community. One of the most well-known is the Legg-Hutter model for a universal intelligence:[^1]

$$ \Upsilon(\sigma) = \sum_{\mu \in E} 2^{-K(\mu)} V(\mu, \sigma) $$

The parallel is clear. Both our $K_{system}$ and their $\Upsilon$ are summing up an agent's (or a system's) performance over a vast space of possible goals or environments. We have defined freedom as a measure of a society's **collective problem-solving capacity**—its ability to empower its citizens to achieve their chosen objectives.

### Embedding Fairness in the Definition

The use of the product operator $\prod_i P(g_i)$ inside the sum is a crucial choice. It defines a "successful outcome" for any given goal vector as one of mutual success. A sum would have valued a scenario where half the people succeed wildly and half fail completely. The product, however, is maximized when success is distributed as evenly as possible. This formulation is known as the Nash Social Welfare Function, and it is a common choice in the formal study of social choice.[^2][^3] An outcome where even one person's probability of success $P(g_i)$ is zero results in a score of zero for that entire joint goal. This embeds a principle of non-domination and a preference for egalitarian outcomes directly into our measure of societal success.

### On the Equality of Goals

This framework is neutral about which goals people should have. The sum $\sum_{\gamma \in G_{joint}}$ treats every combination of human aspiration as equally worthy of consideration.

However, the *consequences* of these goals are not treated equally by the system's dynamics. This influence is captured in the Nash Equilibrium $\sigma^*(\gamma)$. Your goal to become a doctor creates positive externalities that alter the equilibrium, making it easier for others to achieve their goals (e.g., "survive an illness"). Conversely, consider an individual whose goal is to "get to work as fast as possible by driving recklessly." Their actions would create negative externalities, drastically lowering the success probabilities $P(g_i)$ for countless other commuters. Our $K_{system}$ formula inherently penalizes societies that allow such destructive goals to destabilize the system and harm others.

### Next Steps: Designing the Game of Society

It is important to be clear: the purpose of this framework is not to calculate a $K_{system}$ score for any real-world society. Such a calculation would be computationally impossible, requiring us to sum over an infinite set of goals and find equilibria for games with billions of players.

Rather, $K_{system}$ is a **conceptual objective function**. Its value is in allowing us to study small, toy systems and ask formal questions. By designing mechanisms for these toy systems and observing which ones maximize $K_{system}$, we can gain insight into the properties of good societal rules. Do K-maximizing mechanisms look like democracy? Do they protect individual rights? These are the questions this framework allows us to formally investigate.

The challenge of political philosophy can therefore be framed as a problem in **mechanism design**—the art of designing the rules of a game to achieve a desired outcome. We do this by designing the mechanism, $m$—the fundamental rules of the game (a constitution, laws, property rights). The mechanism doesn't determine the outcome directly; it **induces a game**. By changing the rules $m$, we change the payoff structure and available actions, which in turn changes the resulting Nash Equilibrium $\sigma^{* }(\gamma, m)$ and the associated success probabilities $P(g_i \mid ...)$.

The optimization problem is therefore:

$$ m^* = \underset{m}{\text{argmax}} [ K_{system}(m) ] $$

In plain English: The best society ($m^*$) is the one whose fundamental rules ($\text{argmax}_m$) create a game where the stable pattern of behavior that emerges from everyone independently pursuing their own goals results in the highest possible capacity for collective success, across all possible futures.

This gives us a formal basis for the next stage of this project: to analyze democracy not as a moral axiom, but as a candidate mechanism, and to test its ability to solve this problem.

---
[^1]: Legg, S., & Hutter, M. (2007). *Universal Intelligence: A Definition of Machine Intelligence*. Minds and Machines, 17(4), 391-444.
[^2]: The formal study of social welfare functions was pioneered by Kenneth Arrow in his 1951 book *Social Choice and Individual Values*.
[^3]: This formulation is known as the Nash Social Welfare Function, derived from the principles in John Nash's 1950 paper, *The Bargaining Problem*.
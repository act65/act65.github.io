---
title: "Automatic integration"
subtitle: "Like automatic differentiation, but for integration"
layout: post
permalink: /autoint
categories: 
  - "research"
scholar:
  bibliography: "auto-int.bib"
---

Automatic differentiation has proven its awesome utility, especially within machine learning {% cite baydin2018automaticdifferentiationmachinelearning %}.
Fasciliting the training of deep neural networks, it has become a staple of the field.

However, as far as I know, there is no analog for automatic integration.
Why not? Where is it? What would it look like?

I'll use this page collect my thoughts on the subject.

- (WIP) I try to [motivate]({{site.baseurl}}/autoint/motivation) the need for automatic integration. What kind of problems could it solve? How could it be used?
- (WIP) I cover [automatic differentiation]({{site.baseurl}}/autoint/autograd) and how it works.
- (WIP) A tutorial on [symbolic integation]({{site.baseurl}}/autoint/symbolic-int) and why its so hard (it's not a closed operation).
- (WIP) An exploration of the [history of integration]({{site.baseurl}}/autoint/history) and how it has been automated in the past.
- (WIP) A [tutorial on calculus]({{site.baseurl}}/autoint/calculus). Back to basics!
- (WIP) A [literature review]({{site.baseurl}}/autoint/lit-review) of recent integration ideas.

<!-- - [State of integration tools]({site.baseurl}/autoint/state-of-int) -->
<!-- - [This]({site.baseurl}/autoint/numerical-int) post explores numerical integration and why its so useful, but also limited. -->

## Bibliography

{% bibliography --cited %}
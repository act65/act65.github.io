---
title: "Projection into the typical set: PITS"
subtitle: "A new approach to solving inverse problems"
layout: post
permalink: /pits
categories: 
  - "research"
scholar:
  bibliography: "pits.bib"
---

The advances in generative modelling have shown that we can generate high-quality samples from complex distributions.
A next step is to use these generative models as priors to help solve inverse problems.

To solve inverse problems usinbg a prior, we normally require the ability to evaluate likelihoods ($p(x)$). However, diffusion models {% cite song2021scorebasedgenerativemodelingstochastic %} do not support likelihood estimates, only generating samples. Thus inverse problem solvers revert to sampling from the posterior to generate solutions {% cite chung_diffusion_2023 %}. Though it's best to think of these 'solutions' as proposals, as there is no guarantee on quality or accuracy.

Neural flows {% cite albergo_stochastic_2023 liu_flow_2022 lipman_flow_2023 %} have recently achieved s.o.t.a {% cite esser2024scalingrectifiedflowtransformers %} and do support likelihood estimates. They can be used to find the local maximum of the posterior {% cite benhamu2024dflowdifferentiatingflowscontrolled %}. However, differentiating through a flow is extremely expensive.

So, it seems that solving inverse problems via a principled approach like MAP is not quite possible with s.o.t.a generative models.
Maybe we can provide a viable alternative.

***

Inverse problems are a class of problems where we want to find the input to a function given the output. For example (within generative machine learning) we care about;

- image recoloring, where we want to find the original image given the black and white image.
- image inpainting, where we want to find the original image given the image with a hole in it.
- speech enhancement, where we want to find the clean speech given the noisy speech.

We consider the setting where we have access to a prior $p(x)$ (e.g. normal, clear speech) and likelihood function $p(y \mid x)$ (the environment adding background noise and interference). We observe $y$ and want to recover $x$. 

Using Bayes rule, we can write the posterior and our goal as;

$$
\begin{align*}
p(x | y) &= \frac{p(y | x) p(x)}{p(y)} \tag{posterior} \\
x^* &= \arg \max_x p(x | y) \tag{the MAP solution}
\end{align*}
$$

> MAP will return the most likely value of $x$, given $y$.
However, is the most likely value of $x$ the 'best' guess?

We offer an alternative approach, suggesting that our guess of $x$ should be typical of the prior. 
We write this as;

$$
\begin{align*}
x^* &= \arg \max_{x \in \mathcal T(p(x))_\epsilon} p(y | x) \tag{PITS}
\end{align*}
$$

where $\mathcal T(p(x))_\epsilon$ is the $\epsilon$-typical set of $p(x)$. We call this Projection Into the Typical Set (PITS).

<!-- Note: This assumes we are working in high enough dimensions that the typical set has concentrated and any sample from the prior is very likely to be typical. -->

I wrote a few posts to help you understand PITS;

[1.]({{ site.baseurl }}/pits/typical) Background on typicality \
[2.]({{ site.baseurl }}/pits/map) A simple worked example showing that MAP produces solutions that are not typical. \
[3.]({{ site.baseurl }}/pits/arbitrary-typical) Using neural flows we can approximate the typical set for arbitrary distributions. \
[4.]({{ site.baseurl }}/pits/inverse) (WIP) How to combine typicality with flows to solve inverse problems. \
[5.]({{ site.baseurl }}/pits/mnist-demo) (WIP) A demonstration of the PITS+flow approach to inverse problems. \
[6.]({{ site.baseurl }}/pits/non-typical) (WIP) Does it matter if solutions are not typical? \
[7.]({{ site.baseurl }}/pits/review-dps) A brief review of methods attempting to solve inverse problems using s.o.t.a  generative models.

<!-- 
As we saw in the background on typicality. Likelihood is not always representative of what we would see in the real world.


 -->

<!-- A main advantage of the PITS approach is that it provides a way to control the quality (/typicality) of the solutions. -->

<!-- what if the true x is not typical? -->
<!-- why not find the MAP solution and then project it into the typical set? -->

<!-- why is it a problem if my diffusion model produces samples that are not typical? -->

## Bibliography

{% bibliography --cited %}

***

These ideas were generated while studying at [VUW](https://www.wgtn.ac.nz/) with [Bastiaan Kleijn](https://people.wgtn.ac.nz/bastiaan.kleijn) and [Marcus Frean](https://people.wgtn.ac.nz/marcus.frean). I was funded by [GN](https://www.gn.com/).
---
---
References
==========

@incollection{coverthomas2006,
    title = {Elements of Information Theory},
    author = {Cover, Thomas M. and Thomas, Joy A.},
    year = {2006},
    publisher = {Wiley-Interscience},
    address = {Hoboken, NJ},
    edition = {2nd},
    isbn = {978-0-471-24195-9},
    url = {https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959},
}

@misc{benhamu2024dflowdifferentiatingflowscontrolled,
      title={D-Flow: Differentiating through Flows for Controlled Generation}, 
      author={Heli Ben-Hamu and Omri Puny and Itai Gat and Brian Karrer and Uriel Singer and Yaron Lipman},
      year={2024},
      eprint={2402.14017},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.14017}, 
}

@misc{song2022denoisingdiffusionimplicitmodels,
      title={Denoising Diffusion Implicit Models}, 
      author={Jiaming Song and Chenlin Meng and Stefano Ermon},
      year={2022},
      eprint={2010.02502},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.02502}, 
}

@misc{chung2024diffusion,
      title={Diffusion Posterior Sampling for General Noisy Inverse Problems}, 
      author={Hyungjin Chung and Jeongsol Kim and Michael T. Mccann and Marc L. Klasky and Jong Chul Ye},
      year={2024},
      eprint={2209.14687},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{chung_diffusion_2023,
	title = {Diffusion {Posterior} {Sampling} for {General} {Noisy} {Inverse} {Problems}},
	url = {http://arxiv.org/abs/2209.14687},
	abstract = {Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which signiﬁcantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efﬁciently handle general noisy (non)linear inverse problems via approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efﬁciently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring. Code is available at https: //github.com/DPS2022/diffusion-posterior-sampling.},
	language = {en},
	urldate = {2024-03-31},
	publisher = {arXiv},
	author = {Chung, Hyungjin and Kim, Jeongsol and Mccann, Michael T. and Klasky, Marc L. and Ye, Jong Chul},
	month = feb,
	year = {2023},
	note = {arXiv:2209.14687 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2023 spotlight},
	file = {Chung et al. - 2023 - Diffusion Posterior Sampling for General Noisy Inv.pdf:/local/scratch/telfaralex/Zotero/storage/62AKCA4K/Chung et al. - 2023 - Diffusion Posterior Sampling for General Noisy Inv.pdf:application/pdf},
}

@misc{song_pseudoinverse-guided_2023,
	title = {Pseudoinverse-{Guided} {Diffusion} {Models} for {Inverse} {Problems}},
	url = {https://openreview.net/forum?id=9_gsMA8MRKQ},
	publisher = {ICML},
	author = {Song, Jiaming and Vahdat, Arash and Mardani, Morteza and Kautz, Jan},
	year = {2023},
	file = {4924_pseudoinverse_guided_diffusion.pdf:/local/scratch/telfaralex/Zotero/storage/ZUYGBBC7/4924_pseudoinverse_guided_diffusion.pdf:application/pdf},
}

@misc{lugmayr_repaint_2022,
	title = {{RePaint}: {Inpainting} using {Denoising} {Diffusion} {Probabilistic} {Models}},
	shorttitle = {{RePaint}},
	url = {http://arxiv.org/abs/2201.09865},
	abstract = {Free-form inpainting is the task of adding new content to an image in the regions specified by an arbitrary binary mask. Most existing approaches train for a certain distribution of masks, which limits their generalization capabilities to unseen mask types. Furthermore, training with pixel-wise and perceptual losses often leads to simple textural extensions towards the missing areas instead of semantically meaningful generation. In this work, we propose RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting approach that is applicable to even extreme masks. We employ a pretrained unconditional DDPM as the generative prior. To condition the generation process, we only alter the reverse diffusion iterations by sampling the unmasked regions using the given image information. Since this technique does not modify or condition the original DDPM network itself, the model produces high-quality and diverse output images for any inpainting form. We validate our method for both faces and general-purpose image inpainting using standard and extreme masks. RePaint outperforms state-of-the-art Autoregressive, and GAN approaches for at least five out of six mask distributions. Github Repository: git.io/RePaint},
	language = {en},
	urldate = {2024-03-31},
	publisher = {arXiv},
	author = {Lugmayr, Andreas and Danelljan, Martin and Romero, Andres and Yu, Fisher and Timofte, Radu and Van Gool, Luc},
	month = aug,
	year = {2022},
	note = {arXiv:2201.09865 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: We missed out on other diffusion models that work on inpainting. We corrected that and apologize for this mistake},
	file = {Lugmayr et al. - 2022 - RePaint Inpainting using Denoising Diffusion Prob.pdf:/local/scratch/telfaralex/Zotero/storage/5YHMJBFR/Lugmayr et al. - 2022 - RePaint Inpainting using Denoising Diffusion Prob.pdf:application/pdf},
}

@article{kawar_denoising_2022,
	title = {Denoising {Diffusion} {Restoration} {Models}},
	language = {en},
	journal = {Neural Information Processing Systems},
	author = {Kawar, Bahjat and Ermon, Stefano and Elad, Michael and Song, Jiaming},
	year = {2022},
	file = {Kawar et al. - Denoising Diffusion Restoration Models.pdf:/local/scratch/telfaralex/Zotero/storage/SQTKBAKD/Kawar et al. - Denoising Diffusion Restoration Models.pdf:application/pdf},
}

@misc{wang_zero-shot_2022,
	title = {Zero-{Shot} {Image} {Restoration} {Using} {Denoising} {Diffusion} {Null}-{Space} {Model}},
	url = {http://arxiv.org/abs/2212.00490},
	abstract = {Most existing Image Restoration (IR) models are task-speciﬁc, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modiﬁcations. By reﬁning only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration.},
	language = {en},
	urldate = {2024-04-14},
	publisher = {arXiv},
	author = {Wang, Yinhuai and Yu, Jiwen and Zhang, Jian},
	month = dec,
	year = {2022},
	note = {arXiv:2212.00490 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Wang et al. - 2022 - Zero-Shot Image Restoration Using Denoising Diffus.pdf:/local/scratch/telfaralex/Zotero/storage/TLKXMWN4/Wang et al. - 2022 - Zero-Shot Image Restoration Using Denoising Diffus.pdf:application/pdf},
}

@misc{mardani_variational_2023,
	title = {A {Variational} {Perspective} on {Solving} {Inverse} {Problems} with {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2305.04391},
	abstract = {Diffusion models have emerged as a key pillar of foundation models in visual domains. One of their critical applications is to universally solve different downstream inverse tasks via a single diffusion prior without re-training for each task. Most inverse tasks can be formulated as inferring a posterior distribution over data (e.g., a full image) given a measurement (e.g., a masked image). This is however challenging in diffusion models since the nonlinear and iterative nature of the diffusion process renders the posterior intractable. To cope with this challenge, we propose a variational approach that by design seeks to approximate the true posterior distribution. We show that our approach naturally leads to regularization by denoising diffusion process (RED-diff) where denoisers at different timesteps concurrently impose different structural constraints over the image. To gauge the contribution of denoisers from different timesteps, we propose a weighting mechanism based on signal-to-noise-ratio (SNR). Our approach provides a new variational perspective for solving inverse problems with diffusion models, allowing us to formulate sampling as stochastic optimization, where one can simply apply off-the-shelf solvers with lightweight iterates. Our experiments for various linear and nonlinear image restoration tasks demonstrate the strengths of our method compared with state-of-the-art sampling-based diffusion models. The code can be found at GitHub.},
	language = {en},
	urldate = {2024-03-31},
	publisher = {arXiv},
	author = {Mardani, Morteza and Song, Jiaming and Kautz, Jan and Vahdat, Arash},
	month = sep,
	year = {2023},
	note = {arXiv:2305.04391 [cs, math, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
	file = {Mardani et al. - 2023 - A Variational Perspective on Solving Inverse Probl.pdf:/local/scratch/telfaralex/Zotero/storage/V2I3HCLD/Mardani et al. - 2023 - A Variational Perspective on Solving Inverse Probl.pdf:application/pdf},
}

@misc{mardani_variational_2023-1,
	title = {A {Variational} {Perspective} on {Solving} {Inverse} {Problems} with {Diffusion} {Models}},
	url = {http://arxiv.org/abs/2305.04391},
	abstract = {Diffusion models have emerged as a key pillar of foundation models in visual domains. One of their critical applications is to universally solve different downstream inverse tasks via a single diffusion prior without re-training for each task. Most inverse tasks can be formulated as inferring a posterior distribution over data (e.g., a full image) given a measurement (e.g., a masked image). This is however challenging in diffusion models since the nonlinear and iterative nature of the diffusion process renders the posterior intractable. To cope with this challenge, we propose a variational approach that by design seeks to approximate the true posterior distribution. We show that our approach naturally leads to regularization by denoising diffusion process (RED-diff) where denoisers at different timesteps concurrently impose different structural constraints over the image. To gauge the contribution of denoisers from different timesteps, we propose a weighting mechanism based on signal-to-noise-ratio (SNR). Our approach provides a new variational perspective for solving inverse problems with diffusion models, allowing us to formulate sampling as stochastic optimization, where one can simply apply off-the-shelf solvers with lightweight iterates. Our experiments for various linear and nonlinear image restoration tasks demonstrate the strengths of our method compared with state-of-the-art sampling-based diffusion models. The code can be found at GitHub.},
	language = {en},
	urldate = {2024-06-05},
	publisher = {arXiv},
	author = {Mardani, Morteza and Song, Jiaming and Kautz, Jan and Vahdat, Arash},
	month = sep,
	year = {2023},
	note = {arXiv:2305.04391 [cs, math, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
	file = {Mardani et al. - 2023 - A Variational Perspective on Solving Inverse Probl.pdf:/local/scratch/telfaralex/Zotero/storage/U8CWP4Q9/Mardani et al. - 2023 - A Variational Perspective on Solving Inverse Probl.pdf:application/pdf},
}

@article{dou_diffusion_2024,
	title = {{DIFFUSION} {POSTERIOR} {SAMPLING} {FOR} {LINEAR} {INVERSE} {PROBLEM} {SOLVING} — {A} {FILTERING} {PERSPECTIVE}},
	abstract = {Diffusion models have achieved tremendous success in generating highdimensional data like images, videos and audio. These models provide powerful data priors that can solve linear inverse problems in zero shot through Bayesian posterior sampling. However, exact posterior sampling for diffusion models is intractable. Current solutions often hinge on approximations that are either computationally expensive or lack strong theoretical guarantees. In this work, we introduce an efficient diffusion sampling algorithm for linear inverse problems that is guaranteed to be asymptotically accurate. We reveal a link between Bayesian posterior sampling and Bayesian filtering in diffusion models, proving the former as a specific instance of the latter. Our method, termed filtering posterior sampling, leverages sequential Monte Carlo methods to solve the corresponding filtering problem. It seamlessly integrates with all Markovian diffusion samplers, requires no model re-training, and guarantees accurate samples from the Bayesian posterior as particle counts rise. Empirical tests demonstrate that our method generates better or comparable results than leading zero-shot diffusion posterior samplers on tasks like image inpainting, super-resolution, and motion deblur.},
	language = {en},
	author = {Dou, Zehao and Song, Yang},
	year = {2024},
	file = {Dou and Song - 2024 - DIFFUSION POSTERIOR SAMPLING FOR LINEAR INVERSE PR.pdf:/local/scratch/telfaralex/Zotero/storage/WNR9JCH9/Dou and Song - 2024 - DIFFUSION POSTERIOR SAMPLING FOR LINEAR INVERSE PR.pdf:application/pdf},
}

@misc{pokle_training-free_2024,
	title = {Training-free {Linear} {Image} {Inverses} via {Flows}},
	url = {http://arxiv.org/abs/2310.04432},
	abstract = {Solving inverse problems without any training involves using a pretrained generative model and making appropriate modifications to the generation process to avoid finetuning of the generative model. While recent methods have explored the use of diffusion models, they still require the manual tuning of many hyperparameters for different inverse problems. In this work, we propose a training-free method for solving linear inverse problems by using pretrained flow models, leveraging the simplicity and efficiency of Flow Matching models, using theoretically-justified weighting schemes, and thereby significantly reducing the amount of manual tuning. In particular, we draw inspiration from two main sources: adopting prior gradient correction methods to the flow regime, and a solver scheme based on conditional Optimal Transport paths. As pretrained diffusion models are widely accessible, we also show how to practically adapt diffusion models for our method. Empirically, our approach requires no problem-specific tuning across an extensive suite of noisy linear inverse problems on high-dimensional datasets, ImageNet-64/128 and AFHQ-256, and we observe that our flow-based method for solving inverse problems improves upon closely-related diffusion-based methods in most settings.},
	language = {en},
	urldate = {2024-03-30},
	publisher = {arXiv},
	author = {Pokle, Ashwini and Muckley, Matthew J. and Chen, Ricky T. Q. and Karrer, Brian},
	month = mar,
	year = {2024},
	note = {arXiv:2310.04432 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 40 pages, 30 figures. Added additional qualitative results in the appendix},
	file = {Pokle et al. - 2024 - Training-free Linear Image Inverses via Flows.pdf:/local/scratch/telfaralex/Zotero/storage/A4RRNUYE/Pokle et al. - 2024 - Training-free Linear Image Inverses via Flows.pdf:application/pdf},
}

@misc{ho2022classifierfreediffusionguidance,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.12598}, 
}

@misc{song2021scorebasedgenerativemodelingstochastic,
      title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
      author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
      year={2021},
      eprint={2011.13456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.13456}, 
}

@misc{esser2024scalingrectifiedflowtransformers,
      title={Scaling Rectified Flow Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Sumith Kulal and Andreas Blattmann and Rahim Entezari and Jonas Müller and Harry Saini and Yam Levi and Dominik Lorenz and Axel Sauer and Frederic Boesel and Dustin Podell and Tim Dockhorn and Zion English and Kyle Lacey and Alex Goodwin and Yannik Marek and Robin Rombach},
      year={2024},
      eprint={2403.03206},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.03206}, 
}

@misc{albergo_stochastic_2023,
	title = {Stochastic {Interpolants}: {A} {Unifying} {Framework} for {Flows} and {Diffusions}},
	shorttitle = {Stochastic {Interpolants}},
	url = {http://arxiv.org/abs/2303.08797},
	abstract = {A class of generative models that uniﬁes ﬂow-based and diﬀusion-based methods is introduced. These models extend the framework proposed in [1], enabling the use of a broad class of continuoustime stochastic processes called ‘stochastic interpolants’ to bridge any two arbitrary probability density functions exactly in ﬁnite time. These interpolants are built by combining data from the two prescribed densities with an additional latent variable that shapes the bridge in a ﬂexible way. The time-dependent probability density function of the stochastic interpolant is shown to satisfy a ﬁrst-order transport equation as well as a family of forward and backward Fokker-Planck equations with tunable diﬀusion. Upon consideration of the time evolution of an individual sample, this viewpoint immediately leads to both deterministic and stochastic generative models based on probability ﬂow equations or stochastic diﬀerential equations with an adjustable level of noise. The drift coeﬃcients entering these models are time-dependent velocity ﬁelds characterized as the unique minimizers of simple quadratic objective functions, one of which is a new objective for the score of the interpolant density. Remarkably, we show that minimization of these quadratic objectives leads to control of the likelihood for any of our generative models built upon stochastic dynamics. By contrast, we establish that generative models based upon a deterministic dynamics must, in addition, control the Fisher divergence between the target and the model. We also construct estimators for the likelihood and the cross-entropy of interpolant-based generative models, discuss connections with other stochastic bridges, and demonstrate that such models recover the Schr¨odinger bridge between the two target densities when explicitly optimizing over the interpolant.},
	language = {en},
	urldate = {2023-07-25},
	publisher = {arXiv},
	author = {Albergo, Michael S. and Boffi, Nicholas M. and Vanden-Eijnden, Eric},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08797 [cond-mat]},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Mathematics - Probability},
	file = {Albergo et al. - 2023 - Stochastic Interpolants A Unifying Framework for .pdf:/local/scratch/telfaralex/Zotero/storage/ZIMWLRQ9/Albergo et al. - 2023 - Stochastic Interpolants A Unifying Framework for .pdf:application/pdf},
}

@misc{liu_flow_2022,
	title = {Flow {Straight} and {Fast}: {Learning} to {Generate} and {Transfer} {Data} with {Rectified} {Flow}},
	shorttitle = {Flow {Straight} and {Fast}},
	url = {http://arxiv.org/abs/2209.03003},
	abstract = {We present rectiﬁed ﬂow, a surprisingly simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions π0 and π1, hence providing a uniﬁed solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectiﬁed ﬂow is to learn the ODE to follow the straight paths connecting the points drawn from π0 and π1 as much as possible. This is achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are special and preferred because they are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efﬁcient models. We show that the procedure of learning a rectiﬁed ﬂow from data, called rectiﬁcation, turns an arbitrary coupling of π0 and π1 to a new deterministic coupling with provably non-increasing convex transport costs. In addition, recursively applying rectiﬁcation allows us to obtain a sequence of ﬂows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectiﬁed ﬂow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight ﬂows that give high quality results even with a single Euler discretization step.},
	language = {en},
	urldate = {2023-08-03},
	publisher = {arXiv},
	author = {Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
	month = sep,
	year = {2022},
	note = {arXiv:2209.03003 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Liu et al. - 2022 - Flow Straight and Fast Learning to Generate and T.pdf:/local/scratch/telfaralex/Zotero/storage/F7SEBUCV/Liu et al. - 2022 - Flow Straight and Fast Learning to Generate and T.pdf:application/pdf},
}


@article{lipman_flow_2023,
	title = {{FLOW} {MATCHING} {FOR} {GENERATIVE} {MODELING}},
	abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples—which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
	language = {en},
	author = {Lipman, Yaron and Chen, Ricky T Q and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
	year = {2023},
	file = {Lipman et al. - 2023 - FLOW MATCHING FOR GENERATIVE MODELING.pdf:/local/scratch/telfaralex/Zotero/storage/4EP7JY9I/Lipman et al. - 2023 - FLOW MATCHING FOR GENERATIVE MODELING.pdf:application/pdf},
}
---
layout: post
title: Adversarial RL
subtitle: Some ideas
---

In the last few years there has been a lot of study of adversarial machine learning. Adversarial pertubations, adversarial training, adversarial examples, adversarial attacks, adversarial defenses, etc.

What are the motivations for this research?
- To protect industrial applications of ML / RL. Aka security.
- To understand 
- 


## Settings

### A single large reward

The attacker is allowed to insert one large, erroneous reward.
How much can this slow learning?

### 

## References

- [Making machine learning robust against adversarial inputs](https://dl.acm.org/doi/10.1145/3134599)
- [Manipulating SGD with Data Ordering Attacks](https://arxiv.org/abs/2104.09667)
---
layout: post
title: Calculating the average
subtitle: I thought averages were simple.
---

I recently discovered that;

1. the arithmetic mean is one of many [means](#which). It is not always the 'right' mean to use.
2. there is more than one [algorithm](#algol)
for calculating the arithmetic mean. The 'usual' algorithm (sum and divide by N) is not the 'best' algorithm.
3. the mean may [not be representative](#typical) of a typical sample. In fact it can be arbitrarily far from any sample.

<!-- start with a puzzle? -->
<!-- What is the mean-ing of life? -->

Let's explore these revelations in more detail.

## Which mean should we use? And when? <a name="which"></a>

As a quick reminder, what is an average? An average is a single number that represents the 'central tendency' of set of numbers.

There are many formal definitions of an average.
Which is the 'right' definiton? Well, that depends on what you want to do with it.

#### The arithmetic mean

$$
A(a) = \frac{1}{N}\sum a_i
$$

Properties
- the numbers to the left of the mean are balanced by the numbers to the right. The mean is the only number for which the residuals (deviations from the estimate) sum to zero
- Translation and scale invariant. A(a+x) = A + x. A(ax) = aA.
- monotonocity. $A(a) > A(b)$ if $a > b$
- invariance under exchange. $A(a,b) = A(b,a)$

> Notice, what we are essentially saying here is: if every number in our dataset was the same number, what number would it have to be in order to have the same sum as our actual dataset?

#### The geometric mean

$$
G(a) = \bigg(\prod a_i \bigg)^{\frac{1}{N}}
$$

Properties
- 


Equivalently, as the arithmetic mean in logscale:

$$
\exp{\left(\frac {1}{n}\sum \ln a_{i}\right)}
$$

When would we want to use this? When the elements of a combine ???-ly.
For example, what is the average of a 2x, a 3x, and a 13x speed up?

> The geometric mean can be understood in terms of geometry. The geometric mean of two numbers, a and b, is the length of one side of a square whose area is equal to the area of a rectangle with sides of lengths a and b. Similarly, the geometric mean of three numbers, a a, b b, and c c, is the length of one edge of a cube whose volume is the same as that of a cuboid with sides whose lengths are equal to the three given numbers. 

Ie we are summarising ... the data by the volume of a hypercube.

#### The harmonic mean

$$
H(a) = \bigg( \frac{\sum a_i^{-1}}{n} \bigg)^{-1}
$$

> it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones.

use case: rates. average speed.

Why dont we use other equations?

$$
J(a) = \sqrt{\sum a_i^2} \\
$$

***

Wiki! 
- [Central tendency](https://en.wikipedia.org/wiki/Central_tendency)
- [Arithmetic mean](https://en.wikipedia.org/wiki/Arithmetic_mean), [Geometric mean](https://en.wikipedia.org/wiki/Geometric_mean), [Harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean)

__Q__ uestions
- Do there exist variational fns whose minima are the geometric and harmonic means?
- What is the geometric / harmonic mean of a set of numbers that are not all positive? Generalise to complex numbers?
- 


## The 'best' algorithm for calculating the arithmetic mean <a name="algol"></a>

Let's dig deeper into calculating the arithmetic mean. What do we mean by best?
Let's use the most accurate?
<!-- / robust?  what about efficient? -->

### Robust algorithms for calculating averages

As argued above, the mean is not robust to outliers.

Mean of medians. vs median of means.

Near-optimal mean estimators with respect to general norms

What about online mean estimation? How to use mean of medians?

What about a tree of medians? Say n = 3. Then take the median of the first 3 numbers and add that as a parent and forget the original 3.  

https://arxiv.org/abs/1806.06233

Variance reduction?


***

__Q:__ What about robust algorithms for calculating the geometric / harmonic mean??


<!-- max likelihood / max a posteriori take the max of a distribution. ie the mode? -->



## 'Typical' samples<a name="typical"></a>

Consider a n-dimensional Gaussian distribution, with mean $\mu$ and covariance $\sigma I$. As n increases, the samples concentrate on a thin shell around the surface of a hypersphere. This hypersphere has radius $\sqrt{n} \sigma$.

So, the distance between the mean and a typical sample is $\sqrt{n} \sigma$. 

This is what variance measures.
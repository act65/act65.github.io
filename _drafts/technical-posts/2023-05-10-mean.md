---
layout: post
title: Calculating the mean
subtitle: I thought means were simple.
categories:
    - tutorial
---

I recently discovered that;

1. the arithmetic mean is one of many [means](#which). And you need to be careful which one you use.
2. there is more than one [algorithm](#algol) for calculating the arithmetic mean. The 'usual' algorithm (sum and divide by N) is not the 'best' algorithm.
3. the mean may [not be representative](#typical) of what is 'typical'.

<!-- start with a puzzle? -->
<!-- What is the mean-ing of life? -->

Let's explore these revelations in more detail.

## Which mean should we use? And when? <a name="which"></a>

<!-- Let's start with; what is a mean? And why do we care?  -->
Data can be noisy, messy, and hard to interpret. We want a way to summarise the data.
A mean is a way to summarise the data. It seeks to describe the 'center' of the data.

Other ways to summarise data could be by how the data is spread out (variance, standard deviation), or by the shape of the distribution (skewness, kurtosis). 

<!-- Let's define a dataset as a set of of $n$, $d$ dimensional real numbers, $D_n = \{a_1, a_2, ..., a_n\}: a_i \in \mathbb{R}^d$. -->

<!-- a very simple predictive model? -->
<!-- a summary of a dataset -->
<!-- the best single choice when you have to satisfy many  -->


There are many definitions of a mean.
Which is the 'right' definiton? Well, that depends on what you want to do with it.

#### The arithmetic mean

The most intuitive would be a mean that minimises the distances between the data and the mean. 
Then, we can say that the arithmetic truly finds the 'center' of the data.

$$
\mathcal A(D_n) = \frac{1}{n}\sum_{i=1}^n a_i
$$

If we choose our distance metric to be the L2 norm, then the arithmetic mean minimises the sum of the squared distances between the data and the mean.

<aside>
Let $a$ be the arithmetic mean of $D_n$.
Then the sum of the squared distances between the data and the mean is;

$$
\sum_{i=1}^n (a_i - a)^2 = \sum_{i=1}^n (a_i^2 - 2a_i a + a^2) = \sum_{i=1}^n a_i^2 - 2a \sum_{i=1}^n a_i + n a^2
$$

Differentiating with respect to $a$ and setting to zero gives;

$$
\frac{d}{da} \sum_{i=1}^n (a_i^2 - 2a_i a + a^2) = -2 \sum_{i=1}^n a_i + 2na = 0
$$

Thus, $a = \frac{1}{n}\sum_{i=1}^n a_i$.

$$
\mathcal A(D_n) = \mathop{\arg\min}_a \sum_{i=1}^n (a_i - a)^2
$$
</aside>

<!-- Closely related to the expected value of a random variable.

$$
\mathbb{E}[X] = \int x p(x) dx
$$

where $p(x)$ is the probability density function of $X$.
This expected value minimises the expected squared distance between samples of the random variable and the mean, the 'center' of the distribution. -->




<!-- Properties

- the numbers to the left of the mean are balanced by the numbers to the right. The mean is the only number for which the residuals (deviations from the estimate) sum to zero. Like a set of scales with many weights on each side. Where the mean is the fulcrum.
- Translation and scale invariant. A(a+x) = A + x. A(ax) = aA.
- monotonocity. $A(a) > A(b)$ if $a > b$
- invariance under exchange. $A(a,b) = A(b,a)$ -->

> 


<p align="center" width="100%">
    <img width="100%" src="{{ site.baseurl }}/assets/mean/scales.png">
    <!-- caption -->
    <figcaption><i>The numbers to the left of the arithmetic mean are balanced by the numbers to the right</i></figcaption>
</p>

Note, knowing the center tells us nothing about the most likely value of the random variable (the mode) or the value that divides the distribution in half (the median).

<!-- Questions that don't make sense;

- what is the mean animal?
- what is the mean word?

These  -->

#### The geometric mean

> The geometric mean can be understood in terms of geometry. The geometric mean of two numbers, a and b, is the length of one side of a square whose area is equal to the area of a rectangle with sides of lengths a and b. Similarly, the geometric mean of three numbers, a a, b b, and c c, is the length of one edge of a cube whose volume is the same as that of a cuboid with sides whose lengths are equal to the three given numbers. 

Ie we are summarising ... the data by the volume of a hypercube.
What is the volume of a hypercube with side length =mean, such that this volume is the same as the volume of a hypercube with side lengths = data?

$$
G(a) = \bigg(\prod a_i \bigg)^{\frac{1}{N}}
$$

A physical examples of a geometric mean are;
<!-- what are multiplicative pheomenna? amplifiers? -->

I have 5 amplifiers, with gains, 2x, 4x, 6x, 9x, 10x and I want to replace them with 5 amplifiers that have the same gain.
What should the gain of the new amplifiers be?
It's not 2+4+6+9+10 / 5 = 6.2x. It's the geometric mean of 5.1x.

<!-- other multiplicative phenomena?
- growth rates
- ratios
-->

Properties

- ??


Equivalently, as the arithmetic mean in logscale:

$$
\exp{\left(\frac {1}{n}\sum \ln a_{i}\right)}
$$

<summary>LogSumExp</summary>
<details>
The LogSumExp function is a smooth maximum â€“ a smooth approximation to the maximum function.
$$
\log \sum_i \exp(a_i) \approx \max_i a_i
$$
</details>

When would we want to use this? When the elements of a combine ???-ly.

<summary>Decathalon example</summary>
<details>
<p>Consider the decathalon. How should we average the scores across the 10 events?</p>

Currently we use an arithmetic mean to calculate the overall score. But maybe it makes more sense to use the geometric mean.
Getting a score of 0 in one event will result in a 0 overall score. This is because the geometric mean is multiplicative. Thus the geometric mean rewards decathletes who are consistently good across all events.


| Name | 100m | Long jump | Shot put | High jump | 400m | 110m hurdles | Discus | Pole vault | Javelin | 1500m |
|------|------|-----------|----------|----------|------|--------------|--------|------------|---------|-------|
| Bob  | 8.5  | 7.5       | 6.5      | 8.0      | 7.0  | 8.0          | 6.5    | 7.0        | 7.5     | 7.5   |
| Alice| 8.0  | 8.0       | 7.0      | 7.5      | 8.5  | 7.5          | 7.0    | 8.0        | 8.0     | 8.0   |
| Carl | 7.0  | 2.5       | 8.0      | 6.5      | 6.5  | 6.5          | 8.5    | 6.5        | 6.0     | 6.0   |


</details>



#### The harmonic mean

$$
H(a) = \bigg( \frac{\sum a_i^{-1}}{n} \bigg)^{-1}
$$

> it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones.

use case: rates. average speed.



***

Wiki! 
- [Central tendency](https://en.wikipedia.org/wiki/Central_tendency)
- [Arithmetic mean](https://en.wikipedia.org/wiki/Arithmetic_mean), [Geometric mean](https://en.wikipedia.org/wiki/Geometric_mean), [Harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean)

__Q__ uestions
- Do there exist variational fns whose minima are the geometric and harmonic means?
- What is the geometric / harmonic mean of a set of numbers that are not all positive? Generalise to complex numbers?
- 

***

#### Alternatives

Why dont we use other equations?

$$
J(a) = \sqrt{\sum a_i^2} \\
$$

Are there other definitions of a mean that find the 'center'?

Properties a mean should have;

- permutation invariance (the order of the data should not matter)
- translation invariance (the mean of a set of data should be the same as the mean of the same data shifted by a constant - is this true for the geometric mean?)
- scale invariance (the mean of a set of data should be the same as the mean of the same data multiplied by a constant - is this true for the harmonic mean?)
- monotonocity (if all the data is increased, the mean should increase)
- continuity (the mean should be a continuous function of the data)
- differentiability (the mean should be differentiable with respect to the data)
- convexity (the mean should be a convex function of the data)
- uniqueness (there should be only one mean for a given set of data)
- should depend on all the data (the mean should be a function of all the data)

## The 'best' algorithm for calculating the arithmetic mean <a name="algol"></a>

Let's dig deeper into calculating the arithmetic mean. 
What do we mean by 'best'?

We could define best by;
- reliable accuracy (how close is the estimate to the true mean)
- efficiency (how long does it take to calculate the estimate)

Let's use the most accurate.

### Probably approximately correct

It's possible to show that the empirical mean (the arithmetic mean) is the optimal estimator of the population mean when the data is normally distributed (a Gaussian distribution).
But is suboptimal when the data is sub-Gaussian, ???

Define L-sub-Gaussian.
$$

$$

Mean of medians. vs median of means.

Near-optimal mean estimators with respect to general norms

What about online mean estimation? How to use mean of medians?

What about a tree of medians? Say n = 3. Then take the median of the first 3 numbers and add that as a parent and forget the original 3.  

https://arxiv.org/abs/1806.06233

Variance reduction?


### Efficient algorithms

<!-- want to look at streaming algols?? -->

Calculating the arithmetic mean is a simple task.
The 'usual' algorithm is to sum the data and divide by the number of data points.
This requires $O(n)$ operations.




***


__Q:__ What about robust algorithms for calculating the geometric / harmonic mean??


<!-- max likelihood / max a posteriori take the max of a distribution. ie the mode? -->



## 'Typical' samples<a name="typical"></a>

Samples can lie arbitrarily far from the 'center' / mean.


Consider a bi-modal distribution.
With (sharp) modes at -x and x. The mean is 0. But, we would never see a sample at 0.

Stranger than this example is a high dimensional Gaussian distribution, with mean $\mu$ and covariance $\sigma I$. As n increases, the samples concentrate on a thin shell around the surface of a hypersphere. This hypersphere has radius $\sqrt{n} \sigma$.
Thus the samples are a factor of $\sqrt{n}$ away from the mean.
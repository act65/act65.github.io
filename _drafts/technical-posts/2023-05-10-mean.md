---
layout: post
title: Being average is humbling
subtitle: There is more to averages than I thought!
---

Typically, for 'neural regression' we minimise a loss function like;

$$
\mathcal L(\theta) = \sum_{i} \parallel y_i - f(x_i; \theta) \parallel^2
$$

But what if we replace the neural network, $f(x_i)$, with a constant?

$$
\mathcal L(\theta) = \sum_{i} \parallel y_i - \theta \parallel^2
$$

Don't be fooled by the simplicity of this idea. There is a lot to it.
We have traded accuracy for understandability.


<!-- start with a puzzle? -->
<!-- What is the mean-ing of life? -->

I thought averages were simple. I was wrong.

I recently disocvered that;

- the arithemtic mean is one of many means. It is not always the 'right' mean to use.
- there is more than one algorithm for calculating the arithemtic mean. The 'usual' algorithm (sum and divide by N) is not the 'best' algorithm.


<aside>

What is an average? What is it for?

How are means used?
- For making a prediction about the next data point. (average rainfall in november is 50mm. therefore it is likely to rain ~50mm this november)
- to compare. (the average rainfall in NZ is 100mm. the average rainfall in Aus is 50mm. therefore it rains more in Aus than NZ)
- to compress / simplify data. i have a variable interest rate that changes weekly. what is the equivalent fixed interest rate over the last 5 years? its the geometric average of the weekly interest rates. (no this is wrong. it ignores compounding.)
- 

what are the other ways to compress data into a single number?
- if we give up the requirement that the number is interpretable then ... ML...
- 

We have lots of data. We want to summarise it.
What does all this data tell us?

Imagine we want to answer the question; are people in NZ or Aus more wealthy?
One way to answer this question would be to pair up ...

When the maginitude is important.
Likelihood of rain (\< x ) is more pertinent than the average rainfall.

> a number that represents the most likely value from a probability distribution

We can summarise data with;
- a single number
- two numbers (mean and variance, gradient and intercept, )
- ???


There are a lot of cases where an average would be of little interest.
- What is the average frequency of a piano concerto?
- What is the average colour of a rainbow?
- ...


</aside>

There are many formal definitions of an average.
Which is the 'right' definiton? Well, that depends on what you want to do with it.

### The arithmetic mean

$$
A(a) = \frac{1}{N}\sum a_i
$$

Properties
- the numbers to the left of the mean are balanced by the numbers to the right. The mean is the only number for which the residuals (deviations from the estimate) sum to zero
- Translation and scale invariant. A(a+x) = A + x. A(ax) = aA.
- monotonocity. $A(a) > A(b)$ if $a > b$
- invariance under exchange. $A(a,b) = A(b,a)$

> Notice, what we are essentially saying here is: if every number in our dataset was the same number, what number would it have to be in order to have the same sum as our actual dataset?

### The geometric mean

$$
G(a) = \bigg(\prod a_i \bigg)^{\frac{1}{N}}
$$

Properties
- 


Equivalently, as the arithmetic mean in logscale:

$$
\exp{\left({{\frac {1}{n}}\sum \ln a_{i}}\right)}
$$

When would we want to use this? When the elements of a combine ???-ly.
For example, what is the average of a 2x, a 3x, and a 13x speed up?

> The geometric mean can be understood in terms of geometry. The geometric mean of two numbers, a a and b b, is the length of one side of a square whose area is equal to the area of a rectangle with sides of lengths a a and b b. Similarly, the geometric mean of three numbers, a a, b b, and c c, is the length of one edge of a cube whose volume is the same as that of a cuboid with sides whose lengths are equal to the three given numbers. 

Ie we are summarising ... the data by the volume of a hypercube.

### The harmonic mean

$$
H(a) = \bigg( \frac{\sum a_i^{-1}}{n} \bigg)^{-1}
$$

> it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones.

use case: rates. average speed.

<aside>
## Optimal solutions

Averages as minimisers of cost functions.
Mean, median and mode.

$$
\mathop{\text{argmin}}_x \sum_i (x - x_i)^2
$$

$$
\mathop{\text{argmin}}_x \sum_i (x - x_i)^1
$$

$$
\mathop{\text{argmin}}_x \sum_i (x - x_i)^0
$$

***

(no. only for 2 numbers in the data)
$$
A(a)H(a) = G(a)^2
$$


Questions
- Do there exist variational fns whose minima are the geometric and harmonic means??
- What is the geometric / harmonic mean of a set of numbers that are not all positive? Generalise to complex numbers?
- 

</aside>

***
<!-- ## Robust algorithms for calculating averages -->

Let's dig deeper into calculating the arithmetic mean.

Something that surprised me was that the 'usual' algorithm for calculating the mean (sum and divide by N). Is not the 'best' algorithm for calculating the mean.

If we are using the arithmetic mean to summarise information about what is normal / expect for the data, then we want to be robust to outliers. 

Mean of medians. vs median of means.

Near-optimal mean estimators with respect to general norms

What about online mean estimation? How to use mean of medians?

What about a tree of medians? Say n = 3. Then take the median of the first 3 numbers and add that as a parent and forget the original 3.  

https://arxiv.org/abs/1806.06233

<!-- ## Efficient algorithms for calculating averages

Reduce all.
Gossip.

Variance reduction? -->

## Clustering

> Instead of a single central point, one can ask for multiple points such that the variation from these points is minimized.

Where k-means minimises the l2 norm, like how the arithmetic mean minimises the l2 norm.


Related reading and references

Wiki! 
- [Central tendency](https://en.wikipedia.org/wiki/Central_tendency)
- [Arithmetic mean](https://en.wikipedia.org/wiki/Arithmetic_mean), [Geometric mean](https://en.wikipedia.org/wiki/Geometric_mean), [Harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean)


<!-- max likelihood / max a posteriori take the max of a distribution. ie the mode? -->
https://arxiv.org/pdf/1403.5556

The rational approach to RL?!


Failure of Thomspon sampling for MABs?
Compared to BAI then exploit?

Say we have 100 arms. And 9 large rewards and 1 VERY large reward.
If the Thompson sampler sees one of the 9, it will increase the probability of choosing it? (thus reducing the probability of the VERY large reward?)

I guess it's all about what priors Thompson sampling starts with?
---
title: "Automatic integration"
subtitle: "Where is it?"
layout: post
categories:
    - "proposal"
scholar:
  bibliography: "auto-int.bib"
---

Automatic differentiation has proven its awesome utility, especially within machine learning {% cite baydin2018automaticdifferentiationmachinelearning %}.
Fasciliting the training of deep neural networks, it has become a staple of the field.

However, as far as I know, there is no analog for automatic integration.
Why not?

***

<!-- uses / motivation -->

Firstly, what kind of problems could automatic integration solve?

<!-- bayesian -->
Two distributions.

$$
\begin{align}
p(y| x) &= \frac{p(x| y) p(y)}{p(x)} \\
p(x) &= \int p(x| y) p(y) dy
\end{align}
$$

For example, we have a prior distribution over likely diseases $p(y)$ and a likelihood function $p(x| y)$ which tells us how likely the observed MRI $x$ is given the disease $y$.
Where $p(y)$ is derived from the population statistics. And $p(x | y)$ is a generative model learning from data.
<!-- y= discrete variable. 1000 different potential diseases -->
<!-- y= continuous variable. how long are they likely to survive / how long until surgery is needed. measured in weeks. e.g 10.24 weeks. -->





$$
\int p(x; \theta) f(x; \phi) dx
$$

where $p(x; \theta)$ is a probability distribution and $f(x; \phi)$ is a function.
{% cite JMLR:v21:19-346 %}

or the Wave equation

$$
\frac{\partial^2 u}{\partial x^2} = c^2 \Delta u
$$

where $u$ is a function and $\Delta$ is the Laplacian operator.
And in general, any PDE.




<!-- what is AD? -->

The key to automatic differentiation is the chain rule.
It allows us to compute the derivative of a function by breaking it down into a sequence of elementary operations.
Calculating their derivatives independently, we can then combine them to get the derivative of the original function.




<!-- current state of integration tools -->



## Bibliography

{% bibliography --cited %}
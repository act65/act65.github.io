---
layout: post
title: Calculating the Mode
subtitle: I thought the mode was simple. I was wrong.
categories:
    - tutorial
permalink: mode
---

I recently discovered a few surprising things about means:

1.  The **arithmetic mean** is just one of many types of [means](#which). Choosing the right one is crucial.
2.  There's more than one [algorithm](#algol) for calculating the arithmetic mean. The standard "sum and divide by N" approach isn't always the 'best'.
3.  The mean might [not always be representative](#typical) of what is 'typical' in a dataset.

Let's explore these revelations in more detail.

<!-- 
- there's only one definition of most common?
    - could mean single most common value
    - location with the highest density
    - (fortunately these two definitions align?)
- algorithms for calculating the mode?
 -->


## 'Typical' Samples and the Mode <a name="typical"></a>

The mean describes the 'center' of a dataset, but individual samples can lie arbitrarily far from this center, and sometimes, the mean itself is not a 'typical' value you'd expect to observe.

Consider a **bi-modal distribution**, for example, with sharp peaks at -5 and +5. The arithmetic mean would be around 0. However, a sample value of 0 might be very unlikely; samples would cluster around -5 or +5. The mean, in this case, falls in a valley, not on a peak.

An even stranger phenomenon occurs in **high-dimensional spaces**. Consider data from a $d$-dimensional Gaussian distribution with mean $\mu$ and covariance $\sigma^2 I$ (where $I$ is the identity matrix). As the dimension $d$ increases, something counter-intuitive happens: most of the data points concentrate in a thin shell around the surface of a hypersphere. The squared distance of a typical point from the mean $\mu$ is approximately $d\sigma^2$. Thus, a typical data point is roughly $\sqrt{d}\sigma$ away from the mean. [^10]

So, if $d$ is large, almost all data points are far from the mean $\mu$! The mean is still the 'center of mass', but it's not where you'd find most of the data. This "concentration of measure" has profound implications for machine learning algorithms that rely on distance measures in high dimensions.



---
**References**

[^1]:
[^10]: Blum, A., Hopcroft, J., & Kannan, R. (2020). *Foundations of Data Science*. Cambridge University Press. (Chapter 2 discusses high-dimensional Gaussians and concentration).
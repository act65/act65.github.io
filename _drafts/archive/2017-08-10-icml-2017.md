---
title: "ICML 2017"
date: "2017-08-10"
layout: post
---

![]({{site.baseurl}}/images/{{page.coverImage}})

Favourite papers from ICML 2017

- [Relative Natural Gradient for Learning Large Complex Models](https://arxiv.org/abs/1606.06069)
- [Lost Relatives of the Gumbel Trick](http://matejbalog.eu/research/lost_relatives_of_the_gumbel_trick.pdf)
- [Orthogonalised ALS](https://arxiv.org/abs/1703.01804)
- [Equivariance Through Parameter-Sharing](https://arxiv.org/abs/1702.08389)
- [Sharp minima can generalise](https://arxiv.org/pdf/1703.04933.pdf)
- [Failures of Gradient-Based Deep Learning](https://simons.berkeley.edu/sites/default/files/docs/6455/berkeley2017.pdf)
- [AdaNet: Adaptive Structural Learning of Artificial Neural Networks](https://arxiv.org/abs/1607.01097)
- [Stochastic generative hashing](https://arxiv.org/pdf/1701.02815.pdf)
- [Optnet: Differentiable Optimization as a Layer in Neural Networks](https://arxiv.org/pdf/1703.00443.pdf)
- [Learning to learn by gradient descent by gradient descent](https://arxiv.org/abs/1606.04474), [Learned Optimizers that Scale and Generalize](https://arxiv.org/abs/1703.04813), [Learning to learn without gradient descent by gradient descent](https://arxiv.org/abs/1611.03824)
- [Synthetic grads](https://arxiv.org/abs/1608.05343) and [understanding synthetic grads](https://arxiv.org/abs/1703.00522)
- [Neural Episodic Control](https://arxiv.org/abs/1703.01988)

I"ê<h3 id="how-does-variance-effect-the-speed-of-learning">How does variance effect the speed of learning?</h3>

<h3 id="how-can-we-reduce-variance">How can we reduce variance?</h3>

<p>Importance sampling and control variates.</p>

<p>Estimating the mean of a function. Not trivial?
How to do efficiently?</p>

<p>When there is high variance in the function ‚Ä¶?</p>

\[\begin{align}
m^* = m + a(t - \tau) \\
a^* = -\frac{Cov(m, t)}{Var(t)} \\
\end{align}\]

<p>Estimating the mean in an incremental fashion</p>

\[\begin{align}
\mu_t &amp;= \sum_{i=0}^t x_i \tag{average}\\
\mu_{t+1} &amp;= \mu_t + a(\mu_t - x_t) \\
a &amp;= \frac{1}{t+1} \\
\end{align}\]

\[\begin{align}
\mu_t &amp;= \sum_{i=0}^t \gamma^ix_i \tag{exponential moving average}\\
\mu_{t+1} &amp;= \mu_t + a(\mu_t - x_t) \\
a &amp;= \beta \tag{some constant value} \\
\end{align}\]

<p>what about other relationships? what would they mean? exp, log, sin,‚Ä¶?</p>

\[\begin{align}
a &amp;=
\end{align}\]

<p>TODO want some images for intuition.</p>
<ul>
  <li>correction of a fn</li>
  <li>effect of variance on accuracy</li>
</ul>

<hr />

<p>What if we care about more than just the mean?</p>
<ul>
  <li>What complicates estimating the variance of a function? Higher order moments? (can we recursively use control variates for each higher order!?)</li>
  <li>What if we want to estimate the entire distribution? Is there a way to use</li>
  <li>what about other p norms? $\mu = \mathop{\text{argmin}}<em>y \sum</em>{i=0}^t \parallel x_i-y\parallel_2$.</li>
</ul>

<hr />

<ul>
  <li>Touch on A2C?</li>
  <li>What about control variates for gradient estimation? (could use synthetic grads?)</li>
</ul>

\[\begin{align}
max E_{s\sim\pi}[R(s)] \\
\\
&amp;= -\nabla log(\pi(s)) R \\
\end{align}\]

<side>(why does less variance me faster learning!? need to motivate)</side>
<p>Advantage actor critic (A2C) improves this byredicng the variance of the gradient estimation</p>
:ET
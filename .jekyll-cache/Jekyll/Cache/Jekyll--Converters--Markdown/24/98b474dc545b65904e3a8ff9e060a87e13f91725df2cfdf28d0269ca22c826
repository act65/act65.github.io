I"€<p>I recently read Judeaâ€™s <a href="https://www.goodreads.com/book/show/36204378-the-book-of-why">book</a> on Causal Inference (you should to). I noticed another interpretation of a couple of the formulas.</p>

<h2 id="causal-inference">Causal inference</h2>

<p>What we care about is the ability to estimate causal relationships from data. Here we consider two methods to estimate a causal relationship using observed data; the front and back door adjustments.</p>

<side>Note: Causal relationships can sometimes be estimated from the data's correlation, but if a confounder is present it complicates the analysis. This is the problem that the front/back door adjustment solve.</side>

<p><img src="\images/smoking.png" alt="pic" /></p>

<p>(<em>$X$ stands for Smoking, $Y$ stands for Cancer, $Z$ stands for Tar and $U$ stands for Smoking gene.</em>)</p>

<side>For more info see Chapter 7. in The Book of Why.
</side>

<h4 id="the-back-door-adjustment">The back door adjustment</h4>

<p>If we are able to close all the back doors (control/remove all paths into $X$ that connect to $Y$) then the causal relationship between $X$ and $Y$ is simply their correlation.</p>

\[\begin{align}
P(Y \mid do(X)) &amp;= \sum_U P(Y \mid X, U=u) P(U=u) \tag{iff all back doors are shut} \\
&amp;= \mathbb E_{u\sim U}[P(Y \mid X, U=u)] \\
P(Y \mid X, U=u) &amp;=  \frac{\mathbb E_{(x, y)\sim X, Y, U=u} [(x -\mu_x)(y-\mu_y)]}{\sigma_x} \tag{correlation}  \\
\\
Y &amp;= aX + bU + c \tag{assume linear relationships} \\
a&amp;= (Y-bU + c)X^{-1} \\
\end{align}\]

<h4 id="the-front-door-adjustment">The front door adjustment</h4>

<p>Now, letâ€™s consider the case where we do not have measurements on the confounder, $U$ but still want to estimate $P(Y \mid do(X))$. Is it still possible? Surprisingly, yes.</p>

<p>a) We can simply estimate the effect of smoking on tar from their correlation as there are no confounders.
b) And we can estimate the effect of tar on cancer by blocking the backdoor, through controlling for smoking.</p>

<p>Or as eqns;</p>

\[\begin{align}
P(Z \mid do(X)) &amp;= P(Z, X) \tag{no back doors to close}\\
P(Y \mid do(Z)) &amp;= \sum_X P(Y, Z, X=x) P(X=x) \tag{close backdoor $Z \to X\to U\to Y$}\\
P(Y \mid do(X)) &amp;= \sum_Z P(Z=z\mid do(X)) \cdot P(Y \mid do(Z=z)) \tag{product rule!?!?}\\
&amp;= \sum_Z P(Z=z, X) \sum_X P(Y\mid X=x, Z=z) P(X=x) \\
\end{align}\]

<h2 id="expected-gradients">Expected gradients</h2>

<p>Cool, now here is the nice part. It all started from the realisation that the correlation coefficient can be rewritten as the expected gradient. I think this generalisation gives the ability to think about causal relationships between cts non-linear relationships between random variables (?).</p>

<h4 id="correlation-and-gradients">Correlation and gradients</h4>

<p>The conditional correlation of two variables is simply the gradient.</p>

\[\begin{align}
P(Y \mid X) &amp;= \mathbb E\big[\frac{(X -\mu_X)(Y-\mu_Y)}{(X -\mu_X)^2} \big] \\
&amp;= \mathbb E\frac{Y-\mu_Y}{X -\mu_X} \\
&amp;= \mathbb E\frac{\Delta Y}{\Delta X} \\
&amp;= \text{expected } \frac{\text{rise}}{\text{run}} \\
&amp;\approx \frac{\partial y}{\partial x} \\
\end{align}\]

<p>Cool, now letâ€™s use this to reinterpret the front and back door adjustments as expectations of gradients.</p>

<p><strong>The backdoor adjustment</strong></p>

\[\begin{align}
P(Y \mid do(X)) &amp;= \mathbb E_u [\frac{\partial y}{\partial x}(u)]  \\
\end{align}\]

<p><strong>The front door adjustment</strong></p>

\[\begin{align}
P(Y \mid do(X)) &amp;= \mathbb E_z [\frac{\partial y}{\partial z}(z) \cdot\frac{\partial z}{\partial x}(x)] \\
\end{align}\]

<p>So the front door adjustment is the application of <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>, nice.</p>

<h2 id="total-causal-effect">Total causal effect</h2>

<p>Not sure if this works as expected. <em>work in progressâ€¦</em></p>

<side>Something is missing here? Would like a measure that returns be between 0-1. Between: does-not-cause vs totally-determined-by. Adding noise should reduce the causal effect.</side>

<p>Want to get an estimate of whether $x$ â€˜causesâ€™ $y$. (<em>specifically sufficient causes</em>)</p>

<p><strong>Desiderata:</strong></p>

<ol>
  <li>If changes in $x$ almost always cause large changes $y$ this should yield high measure of a causal relationship</li>
  <li>If there exists a value of $x$ that cause large changes $y$ but it almost never occurs, then $X$ is not a â€˜sufficient causeâ€™ of $y$.</li>
  <li>the direction of the gradient doesnâ€™t matter, only the magnitude</li>
  <li>only deterministic fns make sense (otherwise the grads are not accurate), aka noise must be an argument.</li>
</ol>

\[c_{x\to y} = \mathbb E [\parallel \frac{\partial y}{\partial x} \parallel_p]\]

<ul>
  <li>Explore relationship to <a href="https://arxiv.org/abs/1703.01365">Integrated Gradients</a></li>
  <li>This captures the notion of sufficient causation(?), what about higher order gradients? Could they be used to capture neseccary casues? $\frac{\partial f^2}{\partial x \partial y}$</li>
  <li>Letâ€™s test this out with some simple fns.$f(x) = x^2$, $f(x,y) =x^T A y$. Want some empirical validation, just for sanity.</li>
</ul>
:ET